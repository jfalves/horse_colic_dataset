---
title: "Horse Colic Dataset"
output: html_notebook
---

```{r set_environment, echo=FALSE}

rm(list = ls())
cat("\014")
```
Este trabalho tem como objetivo analisar alguns algoritmos de _data mining_ a fim de classificar resultados. O dados utilizados foram disponibilizados pela [UCI Machine Learning Database](http://archiove.ics.uci.edu/ml/datasets/Horse+Colic) e trata-se de dados de procedimentos gastrointestinal em cavalos.

O _dataset_ contém dados como idade, temperatura, respiração, contagem de proteínas, entre outras informações de atendimentos veterinários onde há 3 possíveis resultados. O cavalo pode ter **sobrevivido** ao procedimento, pode ter sido proposto a **eutanasia** ou ter ocorrido o **falecimento**. Nesse exemplo iremos inferir a partir dos parametros de atendimento a classe em que o cavalo se insere. 

[Repositório](https://github.com/jfalves/horse_colic_dataset) com o código do projeto.

***

### Análise inicial
É muito importante conhecer os dados antes de tentar aplicar qualquer tipo de inferência, ou seja, fazer uma análise descritiva dos dados. Essa é a etapa mais importante do processo de _data science_.

```{r load_file, echo=FALSE}

train_dataset = read.csv(file="./horse.csv", header=TRUE, sep=",")
test_dataset  = read.csv(file="./horseTest.csv", header=TRUE, sep=",")

show(head(train_dataset,10))
```

Olhando para os dados é possível classificar-los em 4 categorias baseadas nas informações que elas evidenciam sobre o problema, a saber, as categorias são: id, categórico, discreto e a classe a ser predita.

#### 1. Dados Categóricos e a Classe
Os dados categóricos são aqueles que dão informações qualitativas como por exemplo, o atributo **age** que corresponde aos valores _adult_ e _young_. Nesse caso em específico além de categorico o dado é binomial, indicando que só há duas possíveis classificações para ele. Os dados categóricos do problema são:

```{r plot_categorical, echo=FALSE}

class_header = c("outcome")

categorical_header = c( "surgery"
                      , "age"
                      , "temp_of_extremities"
                      , "peripheral_pulse"
                      , "mucous_membrane"
                      , "capillary_refill_time"
                      , "pain"
                      , "peristalsis"
                      , "abdominal_distention"
                      , "nasogastric_tube"
                      , "nasogastric_reflux"
                      , "rectal_exam_feces"
                      , "abdomen"
                      , "abdomo_appearance"
                      , "surgical_lesion"
                      , "lesion_1"
                      , "lesion_2"
                      , "lesion_3"
                      , "cp_data" )

# Converte colunas para tipo categórico
train_dataset['lesion_1'] = as.factor(train_dataset[, 'lesion_1'])
train_dataset['lesion_2'] = as.factor(train_dataset[, 'lesion_2'])
train_dataset['lesion_3'] = as.factor(train_dataset[, 'lesion_3'])

par(mfcol=c(1,3), mar=c(6,2,3,2))

for(header in append(categorical_header,class_header))
  barplot( summary.factor(train_dataset[header])
         , main = header
         , las=2)

```

Já com essa leitura podemos identificar alguns problemas como:

* Quantidade de valores Nulos em determinados parametros;
* Desbalanceamento entre as 3 classes de inferência;
* Para os parametros **lesion_1**, **lesion_2** e **lesion_3**, apesar de numéricos, representam categorias da lesão;

#### 2. Dados Discretos
Os dados discretos ou no caso discretizados, pois derivam de dados contínuos, são representações númericas de algum parametro, como por exemplo, **pulse** que representa o pulso do cavalo em um determinado momento do procedimento médico. Os dados discretos do problema são:

```{r plot_discret, echo=FALSE}

discrete_header = c( "rectal_temp"
                   , "pulse"
                   , "respiratory_rate"
                   , "nasogastric_reflux_ph"
                   , "packed_cell_volume"
                   , "total_protein"
                   , "abdomo_protein" )

# Conta a quantidade de nulos por coluna 
show(sapply(train_dataset[discrete_header], function(x) sum(is.na(x))))

par(mfcol=c(1,3), mar=c(6,2,3,2))

for(header in discrete_header)
  boxplot( train_dataset[header]
         , main = header)
```
Com essa preliminar podemos observar que:

* os dados contêm alguns _outliers_, principalmente em **rectal_temp** e **respiratory_rate**;
* algumas distribuições estão inclinadas positivamente, principalmente **total_protein**;
* as colunas **abdomo_protein** e **nasogastric_reflux_ph** contém alta concentração de nulos;

```{r plot_correlation, echo=FALSE}

pairs(train_dataset[discrete_header])

correlation = cor(train_dataset[discrete_header], use = "pairwise.complete.obs", method="spearman")

show(as.data.frame(correlation))
```

Os dados discretos também não parecem estar linearmente correlacionados.

#### 3. Outros
Com isso falta apenas analisar a coluna **Hospital Number** que representa o atendimento do cavalo, ao contrário do que parece, não é um identificador único uma vez que o cavalo pode ser atendido mais de uma vez por problemas distintos.

Segue abaixo também alguns _insights_ retirados com o especialista do problema:

```
Attribute Information:

1: surgery? 
1 = Yes, it had surgery 
2 = It was treated without surgery 

2: Age 
1 = Adult horse 
2 = Young (< 6 months) 

3: Hospital Number 
- numeric id 
- the case number assigned to the horse (may not be unique if the horse is treated > 1 time) 

4: rectal temperature 
- linear 
- in degrees celsius. 
- An elevated temp may occur due to infection. 
- temperature may be reduced when the animal is in late shock 
- normal temp is 37.8 
- this parameter will usually change as the problem progresses, eg. may start out normal, then become elevated because of the lesion, passing back through the normal range as the horse goes into shock 

5: pulse 
- linear 
- the heart rate in beats per minute 
- is a reflection of the heart condition: 30 -40 is normal for adults 
- rare to have a lower than normal rate although athletic horses may have a rate of 20-25 
- animals with painful lesions or suffering from circulatory shock may have an elevated heart rate 

6: respiratory rate 
- linear 
- normal rate is 8 to 10 
- usefulness is doubtful due to the great fluctuations 

7: temperature of extremities 
- a subjective indication of peripheral circulation 
- possible values: 
1 = Normal 
2 = Warm 
3 = Cool 
4 = Cold 
- cool to cold extremities indicate possible shock 
- hot extremities should correlate with an elevated rectal temp. 

8: peripheral pulse 
- subjective 
- possible values are: 
1 = normal 
2 = increased 
3 = reduced 
4 = absent 
- normal or increased p.p. are indicative of adequate circulation while reduced or absent indicate poor perfusion 

9: mucous membranes 
- a subjective measurement of colour 
- possible values are: 
1 = normal pink 
2 = bright pink 
3 = pale pink 
4 = pale cyanotic 
5 = bright red / injected 
6 = dark cyanotic 
- 1 and 2 probably indicate a normal or slightly increased circulation 
- 3 may occur in early shock 
- 4 and 6 are indicative of serious circulatory compromise 
- 5 is more indicative of a septicemia 

10: capillary refill time 
- a clinical judgement. The longer the refill, the poorer the circulation 
- possible values 
1 = < 3 seconds 
2 = >= 3 seconds 

11: pain - a subjective judgement of the horse's pain level 
- possible values: 
1 = alert, no pain 
2 = depressed 
3 = intermittent mild pain 
4 = intermittent severe pain 
5 = continuous severe pain 
- should NOT be treated as a ordered or discrete variable! 
- In general, the more painful, the more likely it is to require surgery 
- prior treatment of pain may mask the pain level to some extent 

12: peristalsis 
- an indication of the activity in the horse's gut. As the gut becomes more distended or the horse becomes more toxic, the activity decreases 
- possible values: 
1 = hypermotile 
2 = normal 
3 = hypomotile 
4 = absent 

13: abdominal distension 
- An IMPORTANT parameter. 
- possible values 
1 = none 
2 = slight 
3 = moderate 
4 = severe 
- an animal with abdominal distension is likely to be painful and have reduced gut motility. 
- a horse with severe abdominal distension is likely to require surgery just tio relieve the pressure 

14: nasogastric tube 
- this refers to any gas coming out of the tube 
- possible values: 
1 = none 
2 = slight 
3 = significant 
- a large gas cap in the stomach is likely to give the horse discomfort 

15: nasogastric reflux 
- possible values 
1 = none 
2 = > 1 liter 
3 = < 1 liter 
- the greater amount of reflux, the more likelihood that there is some serious obstruction to the fluid passage from the rest of the intestine 

16: nasogastric reflux PH 
- linear 
- scale is from 0 to 14 with 7 being neutral 
- normal values are in the 3 to 4 range 

17: rectal examination - feces 
- possible values 
1 = normal 
2 = increased 
3 = decreased 
4 = absent 
- absent feces probably indicates an obstruction 

18: abdomen 
- possible values 
1 = normal 
2 = other 
3 = firm feces in the large intestine 
4 = distended small intestine 
5 = distended large intestine 
- 3 is probably an obstruction caused by a mechanical impaction and is normally treated medically 
- 4 and 5 indicate a surgical lesion 

19: packed cell volume 
- linear 
- the # of red cells by volume in the blood 
- normal range is 30 to 50. The level rises as the circulation becomes compromised or as the animal becomes dehydrated. 

20: total protein 
- linear 
- normal values lie in the 6-7.5 (gms/dL) range 
- the higher the value the greater the dehydration 

21: abdominocentesis appearance 
- a needle is put in the horse's abdomen and fluid is obtained from 
the abdominal cavity 
- possible values: 
1 = clear 
2 = cloudy 
3 = serosanguinous 
- normal fluid is clear while cloudy or serosanguinous indicates a compromised gut 

22: abdomcentesis total protein 
- linear 
- the higher the level of protein the more likely it is to have a compromised gut. Values are in gms/dL 

23: outcome 
- what eventually happened to the horse? 
- possible values: 
1 = lived 
2 = died 
3 = was euthanized 

24: surgical lesion? 
- retrospectively, was the problem (lesion) surgical? 
- all cases are either operated upon or autopsied so that this value and the lesion type are always known 
- possible values: 
1 = Yes 
2 = No 

25, 26, 27: type of lesion 
- first number is site of lesion 
1 = gastric 
2 = sm intestine 
3 = lg colon 
4 = lg colon and cecum 
5 = cecum 
6 = transverse colon 
7 = retum/descending colon 
8 = uterus 
9 = bladder 
11 = all intestinal sites 
00 = none 
- second number is type 
1 = simple 
2 = strangulation 
3 = inflammation 
4 = other 
- third number is subtype 
1 = mechanical 
2 = paralytic 
0 = n/a 
- fourth number is specific code 
1 = obturation 
2 = intrinsic 
3 = extrinsic 
4 = adynamic 
5 = volvulus/torsion 
6 = intussuption 
7 = thromboembolic 
8 = hernia 
9 = lipoma/slenic incarceration 
10 = displacement 
0 = n/a 
28: cp_data 
- is pathology data present for this case? 
1 = Yes 
2 = No 
- this variable is of no significance since pathology data is not included or collected for these cases
```

A análise exploratória dos dados serve para gerar ideias sobre como o dado está distribuido e quais são os possíveis problemas para a aplicação que iremos desenvolver. Em geral, no processo de construção de _data science_ esse é a etapa mais demorada. 

***

### Pré Processamento dos Dados
Antes de qualquer transformação do dataset original, é interessante relembrar que alguns tratamentos de pré-processamento dos dados como _data imputation_ devem ser aplicados separando treino e teste. Isso ocorre pois devemos evitar o vazamento de informações de teste na massa de treino, ocasionando problemas como a introdução de viéses.

No entanto, no caso em questão, é possível fazer uma preparação dos dados transformando o atributo **lesion_1** em categórico sem essa preocupação. Também nessa etapa, as colunas **lesion_2**, **lesion_3** e **cp_data** serão descartadas pois não trazem informaçãoes úteis, assim como o parametro **hospital_number**. Já as colunas **abdomo_protein** e **nasogastric_reflux_ph** serão removidas pela alta quantidade de valores nulos.

Por fim, a classe _euthanized_ e _died_ serão unificadas para fins de balanceamento dos dados. Também faremos o _data imputaton_ dos dados categóricos por se tratar de uma substituição por um valor fixo, a saber "na". Caso fossemos utilizar métodos estatisticos de substituição como média, moda, regressão, não poderiamos fazê-lo nessa etapa.

```{r pre_processing, echo=FALSE}

data_preprocessing = function(dataset) {
  
  # Remoção das colunas desnecessárias
  dataset = subset( dataset
                  , select = -c( lesion_2
                               , lesion_3
                               , hospital_number
                               , abdomo_protein
                               , nasogastric_reflux_ph
                               , cp_data) )
  
  # Criação dos vetores que traduzirão o número em texto 
  site_lesion_lkp = c( "gastric"
                     , "sm_intestine"
                     , "lg_colon"
                     , "lg_colon_and_cecum"
                     , "cecum"
                     , "transverse_colon"
                     , "retum_descending_colon"
                     , "uterus"
                     , "bladder"
                     , "all_intestinal_sites"
                     , "none" )
  names(site_lesion_lkp) = c(1,2,3,4,5,6,7,8,9,11,99)
  
  type_lesion_lkp = c( "simple"
                     , "strangulation"
                     , "inflammation"
                     , "other" )
  names(type_lesion_lkp) = c(1,2,3,4)
  
  subtype_lesion_lkp = c( "mechanical"
                        , "paralytic"
                        , "na" )
  names(subtype_lesion_lkp) = c(1,2,3)
  
  specific_lesion_lkp = c( "obturation"
                         , "intrinsic"
                         , "extrinsic"
                         , "adynamic"
                         , "volvulus_torsion"
                         , "intussuption"
                         , "thromboembolic"
                         , "hernia"
                         , "lipoma_slenic_incarceration"
                         , "displacement"
                         , "na")
  names(specific_lesion_lkp) = c(1,2,3,4,5,6,7,8,9,10,99)
  
  # Traduz os números em colunas
  lesion_1 = c()
  lesion_2 = c()
  lesion_3 = c()
  lesion_4 = c()
  
  for(index in 1:nrow(dataset["lesion_1"])) {
    lesion = as.numeric(strsplit(as.character(dataset[index,"lesion_1"]), "")[[1]])
    
    if( lesion[1] == 1 & lesion[2] == 1){
      
      lesion[1] = 11
      lesion = lesion[-2]
    } else if(is.integer(lesion[5])){
      
      if(lesion[4] == 1 & lesion[5] == 0){
        
        lesion[4] = 10
        lesion = lesion[-5] 
      }
      
    }
    
    for(column in 1:length(lesion)){
      
      if(lesion[column] == 0){
        lesion[column] = 99
      }
      
      if(column == 1){
        lesion_1[index] = site_lesion_lkp[lesion[column]] 
      } else if(column == 2){
        lesion_2[index] = type_lesion_lkp[lesion[column]]
      } else if(column == 3){
        lesion_3[index] = subtype_lesion_lkp[lesion[column]]
      } else {
        lesion_4[index] = specific_lesion_lkp[lesion[column]]
      }
      
    }
  }
  
  dataset["site_lesion"] = lesion_1
  dataset["type_lesion"] = lesion_2
  dataset["subtype_lesion"] = lesion_3
  dataset["specific_lesion"] = lesion_4
  
  # Replace de missing values
  categorical_header = c( "surgery"
                        , "age"
                        , "temp_of_extremities"
                        , "peripheral_pulse"
                        , "mucous_membrane"
                        , "capillary_refill_time"
                        , "pain"
                        , "peristalsis"
                        , "abdominal_distention"
                        , "nasogastric_tube"
                        , "nasogastric_reflux"
                        , "rectal_exam_feces"
                        , "abdomen"
                        , "abdomo_appearance"
                        , "surgical_lesion"
                        , "site_lesion" 
                        , "type_lesion"
                        , "subtype_lesion"
                        , "specific_lesion" )
  
  dataset = subset(dataset, select = -c(lesion_1) )
  
  index = sapply(dataset, is.factor)
  dataset[index] = lapply(dataset[index], as.character)
  
  for(header in categorical_header) {
    dataset[header][is.na(dataset[header])] = "na"
  }
  
  index = sapply(dataset, is.character)
  dataset[index] = lapply(dataset[index], as.factor)
  
  dataset[class_header][dataset[class_header] == "euthanized"] = "died"
  
  return(dataset)
}

train_dataset = data_preprocessing(train_dataset)
test_dataset = data_preprocessing(test_dataset)

# FIX random forest bug "error - type of predictors in new data do not match"
test_dataset = rbind(train_dataset[1,], test_dataset)
test_dataset = test_dataset[-1,]

# FIX random forest "Can't have empty classes in y."
train_dataset$outcome = factor(train_dataset$outcome)
test_dataset$outcome = factor(test_dataset$outcome) 

categorical_header = c( "surgery"
                      , "age"
                      , "temp_of_extremities"
                      , "peripheral_pulse"
                      , "mucous_membrane"
                      , "capillary_refill_time"
                      , "pain"
                      , "peristalsis"
                      , "abdominal_distention"
                      , "nasogastric_tube"
                      , "nasogastric_reflux"
                      , "rectal_exam_feces"
                      , "abdomen"
                      , "abdomo_appearance"
                      , "surgical_lesion"
                      , "site_lesion" 
                      , "type_lesion"
                      , "subtype_lesion"
                      , "specific_lesion" )

lesion_header = c( "site_lesion"
                 , "type_lesion"
                 , "subtype_lesion"
                 , "specific_lesion" )

par(mfcol=c(1,3), mar=c(6,2,3,2))

for(header in lesion_header)
  barplot( summary.factor(train_dataset[header])
         , main = header
         , las=2)

```

#### Massa de Treino/Teste e _imputation_ dos dados discretos

Como dito anteriormente, vamos separar os dados em massas de treino e teste e depois aplicar um metódo de _imputation_ nos dados discretos, que no nosso caso foi escolhido a média.

```{r test_train_mass, echo=FALSE}

discrete_header = c( "rectal_temp"
                   , "pulse"
                   , "respiratory_rate"
                   , "packed_cell_volume"
                   , "total_protein" )

for(header in discrete_header) {
  
  mean_data = mean(train_dataset[[header]], na.rm = TRUE)
  
  train_dataset[header][is.na(train_dataset[header])] = mean_data
  test_dataset[header][is.na(test_dataset[header])] = mean_data
}

show(train_dataset)
show(test_dataset)
```

***

### Teste dos algoritmos

Depois de toda a preparação, finalmente testaremos alguns modelos preditivos. A princípio utilizaremos _Support Vector Machine_, _K-Nearest Neighbor_, e _Random Forest_.

#### 1. Algoritmo Random Forest
O algoritmo _Random Forest_ utiliza uma estrutura de uma estrutra de árvore selecionando os atributos que mais geram ganho de informação sobre as classes a serem preditas. Nesse exemplo tivemos 1000 árvores e uma acurácia de 100%. Durante o processo foi feito o _tuning_ dos parametros de quantidade de árvores e _splits_ utilizando a bibiliote _**caret**_.

```{r RF_model, echo=FALSE}

#install.packages(c("randomForest","caret"))
library(randomForest)
library(caret)

# Colunas relevantes
RF_header = c( "site_lesion"
             , "type_lesion"
             , "specific_lesion"
             , "packed_cell_volume"
             , "pain"
             , "mucous_membrane"
             , "temp_of_extremities"
             , "abdominal_distention"
             , "pulse"
             , "outcome")

RF_train = train_dataset[RF_header]
RF_test = test_dataset[RF_header]

RF_model = randomForest( formula = outcome ~ .
                       , data = RF_train
                       , importance = TRUE
                       , ntree = 1000
                       , mtry = 7 )

show(importance(RF_model))

predictionsForest = predict(RF_model, RF_test)

tab = table(predictionsForest, RF_test[[class_header]])

show(mean(predictionsForest == RF_test[[class_header]]) * 100)
show(tab)
```

#### 2. Algoritmo K-Nearest Neighbor
Para o algoritmo KNN, a classificação é uma função que mede a distancia do ponto a ser avalidado em relação aos pontos do conjuto de treino. Caso a distancia seja menor para alguma classe, escolhemos essa classe como a resposta da classificação. No exemplo, o conjunto de dados foi discretizados através de duas técnicas chamadas _dummy code_ e _ordinal code_, também ativamos a opção de normalização de dados com um bom resultado na acurácia, 89%. Também foi alterada a quantidade _k_ achando o valor ótimo de 3 vizinhos.

```{r KNN_model, echo=FALSE}

#install.packages(c("dummies","DMwR","anchors"))
library(DMwR)
library(fastDummies)
library(anchors)

KNN_train = train_dataset
KNN_test = test_dataset

# Ordinal code
replace_header = c( "temp_of_extremities"
                  , "peripheral_pulse"
                  , "capillary_refill_time"
                  , "peristalsis"
                  , "abdominal_distention"
                  , "nasogastric_tube"
                  , "nasogastric_reflux"
                  , "rectal_exam_feces"
                  , "abdomo_appearance"
                  , "surgery"
                  , "age" )

replace_dict_from = c( "normal","warm","cool","cold","increased","reduced","absent","less_3_sec","3",
               "more_3_sec","hypermotile","hypomotile","none","slight","moderate", 
               "severe","significant","more_1_liter","less_1_liter","decreased","clear",
               "cloudy","serosanguious","na","yes","no","adult","young" )
replace_dict_to = c(0,1,-1,-2,1,-1,-2,1,0,-1,1,-1,0,-1,-2,-3,-2,-2,-1,-1,0,-1,-2,-5,1,0,1,0)

KNN_train[replace_header] = lapply(KNN_train[replace_header], as.character)
KNN_test[replace_header] = lapply(KNN_test[replace_header], as.character)

for(index in 1:length(replace_dict_from)){
  KNN_train = replace.value( data = KNN_train
                           , names=replace_header
                           , from=replace_dict_from[index]
                           , to=replace_dict_to[index] )
  
  KNN_test = replace.value( data = KNN_test
                          , names=replace_header
                          , from=replace_dict_from[index]
                          , to=replace_dict_to[index] )
}

KNN_train[replace_header] = lapply(KNN_train[replace_header], function(x) as.numeric(as.character(x)))
KNN_test[replace_header]  = lapply(KNN_test[replace_header], function(x) as.numeric(as.character(x)))

# Dummy COde
dummy_header = c( "mucous_membrane"
                , "pain"
                , "abdomen"
                , "surgical_lesion"
                , "site_lesion" 
                , "type_lesion"
                , "subtype_lesion"
                , "specific_lesion" )

KNN_train = dummy_cols( KNN_train
                      , select_columns = dummy_header
                      , remove_first_dummy = TRUE )
KNN_train = KNN_train[!(colnames(KNN_train) %in% dummy_header)]

KNN_test = dummy_cols( KNN_test
                     , select_columns = dummy_header
                     , remove_first_dummy = TRUE )
KNN_test = KNN_test[!(colnames(KNN_test) %in% dummy_header)]

KNN_model = kNN( form = outcome ~ . 
               , train = KNN_train
               , test = KNN_test
               , norm= TRUE
               , k = 3 )

tab = table(KNN_model, KNN_test[[class_header]])

accuracy = function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}

show(accuracy(tab))
show(tab)
```

#### 3. Support Vector Machine
O algoritmo _SVM_ é uma abordagem que separa os dados utlizando um hiperplano em R^n^. Também utiliza-se um núcleo, que nada mais é que uma transformação linear entre dois espaços, esse núcleo é essencial pois introduz a não linearidade no modelo, aumentando a capacidade de abstração. No exemplo foi utilizado o núcleo polinomial ao invés do radial, aumentando a  acurácia de 93% para 96%.

```{r SVM_model, echo=FALSE}

#install.packages("e1071")
library(e1071)

SVM_train = train_dataset
SVM_test = test_dataset

dummy_header = categorical_header

SVM_train = dummy_cols( SVM_train
                      , select_columns = dummy_header
                      , remove_first_dummy = TRUE )
SVM_train = SVM_train[!(colnames(SVM_train) %in% dummy_header)]

SVM_test = dummy_cols( SVM_test
                     , select_columns = dummy_header
                     , remove_first_dummy = TRUE )
SVM_test = SVM_test[!(colnames(SVM_test) %in% dummy_header)]

SVM_model = svm( form = outcome ~ . 
               , data = SVM_train 
               , kernel = "polynomial" )

predictionsSVM = predict(SVM_model, SVM_test)

tab = table(predictionsSVM, SVM_test[["outcome"]])

accuracy = function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}

show(accuracy(tab))
show(tab)
```

***

#### Conclusão
Dos algoritmos testados a melhor performance foi do _Random Forest_com 100% ao contrário da pior performance, 89%, no _KNN_. Também foi obtido boa performance com _SVM_ chegando a 96% de acerto. Acredito que poderia tratar melhor o _dataset_, como por exemplo, a remoção ou normalização de _outliers_. Também devido a natureza dos dados, o data imputation poderia ter sido feito através de regressão linear.